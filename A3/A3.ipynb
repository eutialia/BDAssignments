{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3: Visualization for Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* [Part 1: EDA](#Part-1.-EDA)\n",
    "* [Part 2: Data Analysis](#Part-2:-Data-analysis-with-Matplotlib)\n",
    "* [Submission](#Submission)\n",
    "* [Lab environment](#Lab-environment-for-the-assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The main focus of [our course](https://courses.cs.sfu.ca/2020sp-cmpt-733-g1) is on data analytics. In fact, however, there are many other exciting topics about Big Data, which we cannot cover due to time constraints. [Lecture 3](https://sfu-db.github.io/bigdata-cmpt733/Lectures/lec3.pdf) gave you a brief overview of Visualization. Assignment 3 is designed to deepen your understanding. After completing this assignment, you should be able to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. How to perform visual data analysis using Python?\n",
    "2. How to study the behaviour of a machine learning algorithm using visualization?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As a motivating example of how visualization can bring data to life and clear up misconceptions, consider to watch [Hans Rosling's famous TED talks](https://www.ted.com/playlists/474/the_best_hans_rosling_talks_yo), e.g. \"The best stat's you've ever seen\" from 2006."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Real estate data**\n",
    "\n",
    "Imagine you are data scientist working at a real-estate company. In this week, you job is to analyze the Vancouver's housing price. You first download a dataset from [property_tax_report_2019.zip](property_tax_report_2019.zip). The dataset contains information on properties from BC Assessment (BCA) and City sources in 2019.  You can find the schema information of the dataset from this [webpage](http://data.vancouver.ca/datacatalogue/propertyTaxAttributes.htm). But this is not enough. You still know little about the data. That's why you need to do EDA in order to get a better and deeper understanding of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We first load the data as a DataFrame. To make this analysis more interesting, I added two new columns to the data: `CURRENT_PRICE` represents the property price in 2019; `PREVIOUS_PRICE` represents the property price in 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# before running this, unzip the provided data\n",
    "df = pd.read_csv(\"data/property_tax_report_2019.csv\")\n",
    "\n",
    "df['CURRENT_PRICE'] = df.apply(lambda x: x['CURRENT_LAND_VALUE']+x['CURRENT_IMPROVEMENT_VALUE'], axis = 1)\n",
    "\n",
    "df['PREVIOUS_PRICE'] = df.apply(lambda x: x['PREVIOUS_LAND_VALUE']+x['PREVIOUS_IMPROVEMENT_VALUE'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now let's start the EDA process. \n",
    "\n",
    "**Hint.** For some of the following questions, we provided an example plot (see [link](https://rawgit.com/sfu-db/bigdata-cmpt733/master/Assignments/A3/A3-plots.html)). But note that you do not have to use the same plot design. In fact, we didn't do a good job to follow the *Principles of Visualization Design* in the second half of the slides of [Lecture 3](https://sfu-db.github.io/bigdata-cmpt733/Lectures/lec3.pdf), please review this part by yourself.\n",
    "You should think about how to correct the bad designs in my plots."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1. Look at some example rows\n",
    "Print the first five rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2. Get summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "From the above output, you will know that the data has 28 columns. Please use the describe() function to get the summary statistics of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Please look at the above output carefully, and make sure that you understand the meanings of each row (e.g., std, 25% percentile)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3. Examine missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we are going to perform EDA on a single column (i.e., univariate analysis). We chose `YEAR_BUILT`, which represents in which year a property was built.  We first check whether the column has any missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Write your code below ---\n",
    "# Print the percentage of the rows whose YEAR_BUILT is missing.\n",
    "missing = df['YEAR_BUILT'].isnull().sum(axis=0)\n",
    "all = df['YEAR_BUILT'].size\n",
    "value = format(missing/all*100, '.2f')\n",
    "print(f'Missing Value: {value} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing values are very common in real-world datasets. In practice, you should always be aware of the impact of the missing values on your downstream analysis results."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 4.  Plot a line chart"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We now start investigating the values in the `YEAR_BUILT` column.  Suppose we want to know: \"How many properties were built in each year (from 1990 to 2018)?\" Please plot a line chart to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_groupedby = df.groupby('YEAR_BUILT', as_index=False).count()\n",
    "df_groupedby['# of Properties'] = df_groupedby['PID']\n",
    "ax = sns.lineplot(x='YEAR_BUILT', y='# of Properties', data=df_groupedby[99:])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Please write down the **two** most interesting findings that you draw from the plot. For example, you can say: <font color='blue'>\"Vancouver has about 6300 properties built in 1996 alone, which is more than any other year\"</font>.\n",
    "\n",
    "**Findings**\n",
    "1. [ADD TEXT]\n",
    "2. [ADD TEXT]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 5. Plot a bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next, we want to find that, between 1900 and 2018, which years have the most number of properties been built? Plot a bar chart to show the top 20 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bar = df_groupedby.query('2018 >= YEAR_BUILT >= 1900')\n",
    "df_bar = df_bar.sort_values(by='# of Properties', ascending=False).head(20)\n",
    "ax = sns.catplot(x='YEAR_BUILT', y='# of Properties', data=df_bar, kind='bar', aspect=1.5)\n",
    "ax.set_xticklabels(rotation=-45)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Please write down the **two** most interesting findings that you draw from the plot. \n",
    "\n",
    "**Findings**\n",
    "1. [ADD TEXT]\n",
    "2. [ADD TEXT]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6. Plot a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What's the distribution of the number of properties built between 1990 and 2018? Please plot a histogram to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist = df_groupedby.query('2018 >= YEAR_BUILT >= 1990')\n",
    "ax = sns.distplot(a=df_dist['# of Properties'], hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Please write down the **two** most interesting findings that you draw from the plot. \n",
    "\n",
    "**Findings**\n",
    "1. [ADD TEXT]\n",
    "2. [ADD TEXT]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7. Make a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Suppose we are interested in those years which built more than 2000 properties. Make a scatter plot to examine whether there is a relationship between the number of built properties and the year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scat = df_groupedby[df_groupedby['# of Properties'] > 2000]\n",
    "ax = sns.scatterplot(x=\"# of Properties\", y=\"YEAR_BUILT\", data=df_scat)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Please write down the **two** most interesting findings that you draw from the plot. \n",
    "\n",
    "**Findings**\n",
    "1. [ADD TEXT]\n",
    "2. [ADD TEXT]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Data and Model Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revisit [Assignment 9 from CMPT 732 - Weather prediction](https://coursys.sfu.ca/2018fa-cmpt-732-g1/pages/Assign9#h-predicting-the-weather-how-hard-can-it) and show a deeper analysis of the same temperature data utilizing a simplified version of the model you already have.\n",
    "\n",
    "**Data**\n",
    "\n",
    "The weather data on HDFS `/courses/732/tmax-{1,2,3,4}` spans a large time period and covers many stations around the globe. There are many possible questions to study. Use a python plotting library of your choice, such as matplotlib.\n",
    "\n",
    "**Model**\n",
    "\n",
    "The model from A9 of CMPT 732 was using `'latitude', 'longitude', 'elevation', 'yesterday_tmax', 'day_of_year'` as input features to predict `t_max`. Please retrain your model to only use `'latitude', 'longitude', 'elevation', 'day_of_year'` before proceeding with task (b) below, and include this re-trained `weather-model` in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Tasks**\n",
    "\n",
    "**a)** Produce **one or more figures** that illustrate the **daily max. temperature distribution over the entire globe** and enable **a comparison of different, non-overlapping time periods**, e.g. to reveal temporal trends over longer time periods or recurring seasons.\n",
    "\n",
    "Only show temperatures where you have data available. Take care to handle overplotting of multiple different values into the same point on the figure, which might happen when you have multiple measurements for the same station in a chosen period. By *handle* overplotting we mean, for instance, to aggregate your data to have a clear meaning for the value that is displayed for a particular station, such as max. or average within the period.\n",
    "\n",
    "Here is an example from the web:\n",
    "<img src=\"http://c3headlines.typepad.com/.a/6a010536b58035970c013486e5c5e6970c-pi\"/>\n",
    "\n",
    "**b)** Produce two or more figures that show the result of your re-trained regression model from CMPT 732-A9, i.e. a version of the model that does not use `yesterday_tmax` as extra input feature:\n",
    "\n",
    "**(b1)** Evaluate your model at a grid of latitude, longitude positions around the globe spanning across oceans and continents, leading to a dense plot of temperatures. This could, for instance, look something like the following:\n",
    "<img src=\"http://www.physicalgeography.net/fundamentals/images/jan_temp.gif\"/>\n",
    "You can use a fixed `day_of_year` of your choice. Also, see further hints about `elevation` below.\n",
    "\n",
    "**(b2)** In a separate plot show the regression error of your model predictions against test data. In this case only use locations where data is given, i.e. you may reuse your plotting method from Part 2 (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Comments and Hints**\n",
    "\n",
    "Any imperfections of your trained model that show up in the visualization are fine. In fact, in this example it is a sign of a good visualization, if it enables us to understand shortcomings of the model. You are not marked for the performance of your model from 732-A9 again, but rather for the methods you create here to investigate it. \n",
    "\n",
    "Please attempt to make continent or country borders visible on your map. You can do that either by using library function or by using enough data points, such that the shape of some continents roughly emerges from the data distribution. Out of the different datasets please use one with at least 100k rows.\n",
    "\n",
    "For (b1) you will need elevation information for the points you produce. Have a look at [`elevation_grid.py`](https://github.com/sfu-db/bigdata-cmpt733/blob/master/Assignments/A3/elevation_grid.py) for a possible way to add this info to your choice of coordinates. If you place the accompanying [elevation data](https://github.com/sfu-db/bigdata-cmpt733/blob/master/Assignments/A3/elevations_latlon.npy.gz) in the same folder as the script you can import the module and see `help(evaluation_grid)` for example usage.\n",
    "![](img/elevations.png)\n",
    "`elevation_grid.py` internally stores elevation data as an array at 5 times the resolution of the figure shown here, use the `get_elevations` function to access it."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Submission of Part 2** \n",
    "\n",
    "Please prepare the following components (each has one or two files):\n",
    "\n",
    "1. *Report:* Combine the plots into a PDF document `weather_report.pdf` along with brief captions explaining and discussing the figures. If you decide to produce the PDF using a Jupyter notebook that contains the markdown to render and discuss the figures saved by `weather_plot.py` you can submit it as `weather_report.ipynb`. Submitting the notebook is optional.\n",
    "2. *Code:* Please provide your code to produce the figures in a script `weather_plot.py`, which could be based on the [`weather_test.py`](https://coursys.sfu.ca/2018fa-cmpt-732-g1/pages/Assign9_Hint) from 732-A9. Since you may want to separate the spark code to run on the cluster from the plotting code, you can provide that in an optional script called `weather_spark.py`.\n",
    "Please ensure that all visualization code relevant for marking is in these python scripts.\n",
    "3. Submit the weather model that you are using.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In summary, you need to complete the first part by filling out the first half of this notebook and the second part by following the submission instructions above. Overall, please submit <font color=\"blue\">A3.ipynb</font>, <font color=\"blue\">weather_plot.py</font>, <font color=\"blue\">weather_spark.py</font>, <font color=\"blue\">weather_report.{pdf|ipynb}</font>, and <font color=\"blue\">weather-model</font> to the CourSys activity [Assignment 3](https://courses.cs.sfu.ca/2020sp-cmpt-733-g1/+a3/)."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lab environment for the assignment\n",
    "\n",
    "**Scratch space**\n",
    "\n",
    "Your scratch space allows you to store larger files outside of your home folder, not counting them towards your limited disk quota. To make that space available via a link from your home folder use:\n",
    "```\n",
    "ln -s /usr/shared/CMPT/scratch/<username> ~/scratch\n",
    "```\n",
    "Similar to HDFS on gateway, please treat this space as a shared resource, i.e. remove large temporary files when you're done working with them.\n",
    "\n",
    "**Conda**\n",
    "\n",
    "For the big data lab setup, we have put a few useful python modules, such as `basemap` or `geoviews`, into a shared conda environment. To use the environment call\n",
    "```\n",
    "source activate /usr/shared/CMPT/big-data/condaenv/py36\n",
    "```\n",
    "or prepare once with\n",
    "```\n",
    "mkdir -p ~/.conda/envs\n",
    "ln -s /usr/shared/CMPT/big-data/condaenv/py36 ~/.conda/envs/\n",
    "```\n",
    "and from thereon simply activate using `source activate py36` and, for instance, work with `pyspark` on your local lab machine.\n",
    "\n",
    "**Pip**\n",
    "\n",
    "As alternative to conda you can also just use pip.\n",
    "\n",
    "For instance, create a pip environment called `myenv` in the scratch space (see above)\n",
    "```\n",
    "python -m venv ~/scratch/myenv\n",
    "```\n",
    "Activate: `source ~/scratch/myenv/bin/activate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}